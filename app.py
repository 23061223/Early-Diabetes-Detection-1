# -*- coding: utf-8 -*-
"""Early-Diabetes-Detection

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18ObF3Xx-H6LukYlQLqnhKCr-KBimT9ax
"""

import pandas as pd
import kagglehub
from kagglehub import KaggleDatasetAdapter

file_name = "diabetes_binary_health_indicators_BRFSS2023.csv"

df = kagglehub.load_dataset(
    KaggleDatasetAdapter.PANDAS,
    "luisangelparra/diabetes-health-indicators-dataset",
    file_name,
    pandas_kwargs={
        "sep": ",",
        "header": 0,
        "dtype": None
    }
)

print("Loaded shape:", df.shape)
df.head()

df.describe().T

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(5,4))
sns.countplot(x='Diabetes_binary', data=df, palette='pastel')
plt.title("Diabetes Prevalence (0=No, 1=Yes)")
plt.show()

num_cols = df.select_dtypes(include='number').columns
plt.figure(figsize=(10,8))
sns.heatmap(df[num_cols].corr(), annot=True, fmt='.2f', cmap='coolwarm')
plt.title("Numeric Feature Correlations")
plt.show()

for col in ['BMI', 'PhysHlth', 'MentHlth']:
    plt.figure(figsize=(6,4))
    sns.histplot(df[col], kde=True, color='teal')
    plt.title(col)
    plt.show()

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from imblearn.pipeline import Pipeline as ImbPipeline
from imblearn.over_sampling import SMOTE

SEED = 42

print(df.isna().sum())

X = df.drop(columns=['Diabetes_binary'])
y = df['Diabetes_binary']

X = pd.get_dummies(X, drop_first=True)

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    stratify=y,
    test_size=0.2,
    random_state=SEED
)


preproc_pipe = ImbPipeline(steps=[
    ('scaler', StandardScaler()),
    ('smote',   SMOTE(random_state=SEED))
])

X_train_pp, y_train_pp = preproc_pipe.fit_resample(X_train, y_train)
print("After SMOTE, class distribution:", np.bincount(y_train_pp))

from xgboost import XGBClassifier
from sklearn.metrics import classification_report, roc_auc_score, average_precision_score

model = XGBClassifier(
    eval_metric='aucpr',
    random_state=SEED
)
model.fit(X_train_pp, y_train_pp)

X_test_scaled = preproc_pipe.named_steps['scaler'].transform(X_test)
y_proba = model.predict_proba(X_test_scaled)[:,1]
y_pred  = (y_proba > 0.5).astype(int)

print("ROC-AUC:", roc_auc_score(y_test, y_proba))
print("AUPRC :", average_precision_score(y_test, y_proba))
print(classification_report(y_test, y_pred, target_names=['No Diabetes','Diabetes']))

from sklearn.model_selection import GridSearchCV, StratifiedKFold

full_pipe = ImbPipeline(steps=[
    ('scaler', StandardScaler()),
    ('smote',   SMOTE(random_state=SEED)),
    ('clf',     XGBClassifier(
        use_label_encoder=False,
        eval_metric='aucpr',
        random_state=SEED
    ))
])

param_grid = {
    'clf__n_estimators': [100, 200],
    'clf__max_depth':    [3, 5],
    'clf__learning_rate':[0.01, 0.1]
}
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)

grid = GridSearchCV(
    full_pipe,
    param_grid=param_grid,
    scoring='average_precision',
    cv=cv,
    n_jobs=-1,
    verbose=1
)
grid.fit(X_train, y_train)

print("Best params:", grid.best_params_)
print("Best CV AUPRC:", grid.best_score_)

best_pipe = grid.best_estimator_
y_proba_final = best_pipe.predict_proba(X_test)[:,1]
y_pred_final  = best_pipe.predict(X_test)

print("Test ROC-AUC    :", roc_auc_score(y_test, y_proba_final))
print("Test AUPRC      :", average_precision_score(y_test, y_proba_final))
print(classification_report(y_test, y_pred_final, target_names=['No Diabetes','Diabetes']))

import shap
import matplotlib.pyplot as plt

best_pipe.fit(X_train, y_train)

explainer  = shap.TreeExplainer(best_pipe.named_steps['clf'])
X_test_scaled = best_pipe.named_steps['scaler'].transform(X_test)
shap_values = explainer.shap_values(X_test_scaled)

explanation = shap.Explanation(
    values=shap_values,
    base_values=explainer.expected_value,
    data=X_test_scaled,
    feature_names=X_test.columns.tolist()
)

shap.plots.beeswarm(explanation, max_display=10)
plt.show()

shap.plots.waterfall(explanation[0], max_display=10)
plt.show()

import joblib

joblib.dump(grid.best_estimator_, 'diabetes_pipeline.pkl')

joblib.dump(explainer, 'shap_explainer.pkl')

from fastapi import FastAPI
from pydantic import BaseModel
import pandas as pd
import joblib
import numpy as np
import shap

pipe      = joblib.load('diabetes_pipeline.pkl')
explainer = joblib.load('shap_explainer.pkl')

class Patient(BaseModel):
    BMI:           float
    KidneyDisease: int
    HighBP:        int
    HighChol:      int
    CholCheck:     int
    Asthma:        int
    COPD:          int
    Smoker:        int
    Stroke:        int
    HeartDiseaseorAttack: int
    PhysActivity:  int
    HvyAlcoholConsump:   int
    AnyHealthcare:       int
    NoDocbcCost:         int
    GenHlth:       int
    MentHlth:      float
    PhysHlth:      float
    DiffWalk:      int
    Sex:           int
    AgeGroup:      int
    Education:     int
    Income:        int

app = FastAPI(title="Diabetes Risk API")

@app.post("/predict")
def predict(patient: Patient):
    df = pd.DataFrame([patient.dict()])

    proba = pipe.predict_proba(df)[0,1]
    return {"risk_score": round(proba,4)}

@app.post("/explain")
def explain(patient: Patient):
    df = pd.DataFrame([patient.dict()])
    X_scaled = pipe.named_steps['scaler'].transform(df)
    shap_vals = explainer.shap_values(X_scaled)[0]
    contributions = dict(zip(df.columns, shap_vals.tolist()))
    base_value = float(explainer.expected_value[0])
    return {"base_value": base_value, "contributions": contributions}

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/requirements.txt.gdoc

packages = [
    "fastapi",
    "uvicorn",
    "pandas",
    "numpy",
    "scikit-learn",
    "imbalanced-learn",
    "xgboost",
    "shap",
    "pydantic",
]

with open("requirements.txt", "w") as f:
    f.write("\n".join(packages))

import os
print(os.system("ls -l requirements.txt"))

!head -n 10 requirements.txt

pip install -r requirements.txt

!mkdir -p "/content/drive/MyDrive/Colab Notebooks/my_project"

!mv requirements.txt "/content/drive/MyDrive/Colab Notebooks/my_project/"

!ls "/content/drive/MyDrive/Colab Notebooks/my_project/"

# Commented out IPython magic to ensure Python compatibility.
# %cd "/content/drive/MyDrive/Colab Notebooks/my_project"
!git init
!git add requirements.txt
!git commit -m "Add requirements.txt"
!git remote add origin https://github.com/23061223/Ensemble-Machine-Learning-for-Early-Diabetes-Detection.git  # if not set
!git push -u origin main

!touch main.py
!mkdir -p data notebooks

from fastapi import FastAPI

app = FastAPI()

@app.get("/")
def read_root():
    return {"message": "Hello, FastAPI in Colab!"}

!pip install pyngrok --quiet

import joblib
joblib.dump(model, 'xgboost_model.pkl')

model = joblib.load('xgboost_model.pkl')

import sys
if 'google.colab' in sys.modules:
    !pip install streamlit --quiet

import streamlit as st
import pandas as pd
import joblib
import shap
import matplotlib.pyplot as plt
import kagglehub
from kagglehub import KaggleDatasetAdapter

pipe = joblib.load("/content/diabetes_pipeline.pkl")
explainer = joblib.load("/content/shap_explainer.pkl")

file_name = "diabetes_binary_health_indicators_BRFSS2023.csv"
df = kagglehub.load_dataset(
    KaggleDatasetAdapter.PANDAS,
    "luisangelparra/diabetes-health-indicators-dataset",
    file_name,
    pandas_kwargs={
        "sep": ",",
        "header": 0,
        "dtype": None
    }
)

X_full = df.drop(columns=['Diabetes_binary'])
X_full_encoded = pd.get_dummies(X_full, drop_first=True)
original_cols = X_full.columns


st.title("🩺 Early Diabetes Risk Assessment")


st.sidebar.header("Patient Information")
bmi = st.sidebar.number_input("BMI", min_value=10.0, max_value=60.0)
phys_health = st.sidebar.slider("Physical Health (days)", 0, 30)
ment_health = st.sidebar.slider("Mental Health (days)", 0, 30)
age_group = st.sidebar.selectbox("Age Group", options=range(1,13))
kidney_disease = st.sidebar.selectbox("Kidney Disease", options=[1, 2, 9])
high_bp = st.sidebar.selectbox("High Blood Pressure", options=[0, 1])
high_chol = st.sidebar.selectbox("High Cholesterol", options=[0, 1])
chol_check = st.sidebar.selectbox("Cholesterol Check", options=[0, 1])
asthma = st.sidebar.selectbox("Asthma", options=[1, 2, 9])
copd = st.sidebar.selectbox("COPD", options=[1, 2, 9])
smoker = st.sidebar.selectbox("Smoker", options=[0, 1])
stroke = st.sidebar.selectbox("Stroke", options=[0, 1])
heart_disease_or_attack = st.sidebar.selectbox("Heart Disease or Attack", options=[0, 1])
phys_activity = st.sidebar.selectbox("Physical Activity", options=[0, 1])
hvy_alcohol_consump = st.sidebar.selectbox("Heavy Alcohol Consumption", options=[0, 1])
any_healthcare = st.sidebar.selectbox("Any Healthcare", options=[0, 1])
no_docbc_cost = st.sidebar.selectbox("Could Not See Doctor Because of Cost", options=[0, 1])
gen_hlth = st.sidebar.selectbox("General Health", options=range(1, 6))
diff_walk = st.sidebar.selectbox("Difficulty Walking", options=[0, 1])
sex = st.sidebar.selectbox("Sex", options=[0, 1])
education = st.sidebar.selectbox("Education", options=range(1, 7))
income = st.sidebar.selectbox("Income", options=range(1, 12))


input_data = {col: 0 for col in original_cols}
input_data.update({
    "BMI": bmi,
    "PhysHlth": phys_health,
    "MentHlth": ment_health,
    "AgeGroup": age_group,
    "KidneyDisease": kidney_disease,
    "HighBP": high_bp,
    "HighChol": high_chol,
    "CholCheck": chol_check,
    "Asthma": asthma,
    "COPD": copd,
    "Smoker": smoker,
    "Stroke": stroke,
    "HeartDiseaseorAttack": heart_disease_or_attack,
    "PhysActivity": phys_activity,
    "HvyAlcoholConsump": hvy_alcohol_consump,
    "AnyHealthcare": any_healthcare,
    "NoDocbcCost": no_docbc_cost,
    "GenHlth": gen_hlth,
    "DiffWalk": diff_walk,
    "Sex": sex,
    "Education": education,
    "Income": income
})


if st.sidebar.button("Assess Risk"):
    input_df = pd.DataFrame([input_data])
    input_df = pd.get_dummies(input_df, drop_first=True)

    input_df = input_df.reindex(columns=X_full_encoded.columns, fill_value=0)


    proba = pipe.predict_proba(input_df)[0,1]

    X_scaled = pipe.named_steps['scaler'].transform(input_df)
    shap_vals = explainer.shap_values(X_scaled)[0]
    base_value = explainer.expected_value[1]

    explanation = shap.Explanation(
        values=shap_vals,
        base_values=base_value,
        data=X_scaled,
        feature_names=input_df.columns.tolist()
    )

    tab1, tab2 = st.tabs(["Prediction", "Explanation"])
    with tab1:
        st.metric("Diabetes Risk Score", f"{proba:.2%}")
    with tab2:
        st.subheader("Feature Contributions")
        st.pyplot(shap.plots.waterfall(explanation, max_display=10))

if st.sidebar.button("Assess Risk"):
    input_data = {
        "BMI": bmi,
        "PhysHlth": phys_health,
        "MentHlth": ment_health,
        "AgeGroup": age_group,
        # Add other fields...
    }
    input_df = pd.DataFrame([input_data])

    # Now it's safe to use input_df
    proba = pipe.predict_proba(input_df)[0][1]
    st.metric("Diabetes Risk Score", f"{proba:.2%}")

if st.sidebar.button("Assess Risk"):
    input_data = {
        "BMI": bmi,
        "PhysHlth": phys_health,
        "MentHlth": ment_health,
        "AgeGroup": age_group,
        "KidneyDisease": kidney_disease,
        "HighBP": high_bp,
        "HighChol": high_chol,
        "CholCheck": chol_check,
        "Asthma": asthma,
        "COPD": copd,
        "Smoker": smoker,
        "Stroke": stroke,
        "HeartDiseaseorAttack": heart_disease_or_attack,
        "PhysActivity": phys_activity,
        "HvyAlcoholConsump": hvy_alcohol_consump,
        "AnyHealthcare": any_healthcare,
        "NoDocbcCost": no_docbc_cost,
        "GenHlth": gen_hlth,
        "DiffWalk": diff_walk,
        "Sex": sex,
        "Education": education,
        "Income": income
    }
    input_df = pd.DataFrame([input_data])
    input_df = pd.get_dummies(input_df, drop_first=True)
    input_df = input_df.reindex(columns=X_full_encoded.columns, fill_value=0)

    proba = pipe.predict_proba(input_df)[0,1]

    X_scaled = pipe.named_steps['scaler'].transform(input_df)
    shap_vals = explainer.shap_values(X_scaled)[0]
    base_value = explainer.expected_value[1]

    explanation = shap.Explanation(
        values=shap_vals,
        base_values=base_value,
        data=X_scaled,
        feature_names=input_df.columns.tolist()
    )

    tab1, tab2 = st.tabs(["Prediction", "Explanation"])
    with tab1:
        st.metric("Diabetes Risk Score", f"{proba:.2%}")
    with tab2:
        st.subheader("Feature Contributions")
        fig, ax = plt.subplots()
        shap.plots.waterfall(explanation, max_display=10, show=False)
        st.pyplot(fig)

# Create a file named 'app.py' containing your Streamlit code
streamlit_code = """
import streamlit as st
import pandas as pd
import joblib
import shap
import matplotlib.pyplot as plt
import kagglehub
from kagglehub import KaggleDatasetAdapter

pipe = joblib.load("/content/diabetes_pipeline.pkl")
explainer = joblib.load("/content/shap_explainer.pkl")

file_name = "diabetes_binary_health_indicators_BRFSS2023.csv"
df = kagglehub.load_dataset(
    KaggleDatasetAdapter.PANDAS,
    "luisangelparra/diabetes-health-indicators-dataset",
    file_name,
    pandas_kwargs={
        "sep": ",",
        "header": 0,
        "dtype": None
    }
)

X_full = df.drop(columns=['Diabetes_binary'])
X_full_encoded = pd.get_dummies(X_full, drop_first=True)
original_cols = X_full.columns


st.title("🩺 Early Diabetes Risk Assessment")


st.sidebar.header("Patient Information")
bmi = st.sidebar.number_input("BMI", min_value=10.0, max_value=60.0)
phys_health = st.sidebar.slider("Physical Health (days)", 0, 30)
ment_health = st.sidebar.slider("Mental Health (days)", 0, 30)
age_group = st.sidebar.selectbox("Age Group", options=range(1,14)) # Adjusted max age group to 13 based on describe output
kidney_disease = st.sidebar.selectbox("Kidney Disease", options=[1.0, 2.0, 9.0]) # Use floats as in the dataframe
high_bp = st.sidebar.selectbox("High Blood Pressure", options=[0.0, 1.0])
high_chol = st.sidebar.selectbox("High Cholesterol", options=[0.0, 1.0])
chol_check = st.sidebar.selectbox("Cholesterol Check", options=[0.0, 1.0])
asthma = st.sidebar.selectbox("Asthma", options=[1.0, 2.0, 9.0])
copd = st.sidebar.selectbox("COPD", options=[1.0, 2.0, 9.0])
smoker = st.sidebar.selectbox("Smoker", options=[0.0, 1.0])
stroke = st.sidebar.selectbox("Stroke", options=[0.0, 1.0])
heart_disease_or_attack = st.sidebar.selectbox("Heart Disease or Attack", options=[0.0, 1.0])
phys_activity = st.sidebar.selectbox("Physical Activity", options=[0.0, 1.0])
hvy_alcohol_consump = st.sidebar.selectbox("Heavy Alcohol Consumption", options=[0.0, 1.0])
any_healthcare = st.sidebar.selectbox("Any Healthcare", options=[0.0, 1.0])
no_docbc_cost = st.sidebar.selectbox("Could Not See Doctor Because of Cost", options=[0.0, 1.0])
gen_hlth = st.sidebar.selectbox("General Health", options=range(1, 6))
diff_walk = st.sidebar.selectbox("Difficulty Walking", options=[0.0, 1.0])
sex = st.sidebar.selectbox("Sex", options=[0.0, 1.0])
education = st.sidebar.selectbox("Education", options=range(1, 7))
income = st.sidebar.selectbox("Income", options=range(1, 12))


input_data = {col: 0.0 for col in original_cols} # Initialize with floats
input_data.update({
    "BMI": bmi,
    "PhysHlth": phys_health,
    "MentHlth": ment_health,
    "AgeGroup": float(age_group), # Convert to float
    "KidneyDisease": float(kidney_disease), # Ensure float
    "HighBP": float(high_bp),
    "HighChol": float(high_chol),
    "CholCheck": float(chol_check),
    "Asthma": float(asthma),
    "COPD": float(copd),
    "Smoker": float(smoker),
    "Stroke": float(stroke),
    "HeartDiseaseorAttack": float(heart_disease_or_attack),
    "PhysActivity": float(phys_activity),
    "HvyAlcoholConsump": float(hvy_alcohol_consump),
    "AnyHealthcare": float(any_healthcare),
    "NoDocbcCost": float(no_docbc_cost),
    "GenHlth": float(gen_hlth),
    "DiffWalk": float(diff_walk),
    "Sex": float(sex),
    "Education": float(education),
    "Income": float(income)
})


if st.sidebar.button("Assess Risk"):
    input_df = pd.DataFrame([input_data])
    input_df = pd.get_dummies(input_df, drop_first=True)
    input_df = input_df.reindex(columns=X_full_encoded.columns, fill_value=0)

    proba = pipe.predict_proba(input_df)[0, 1]

    # ✅ Add success message and metric
    st.success("✅ Prediction complete!")
    st.metric(label="Diabetes Risk Score", value=f"{proba:.2%}")

    # SHAP explanation
    X_scaled = pipe.named_steps['scaler'].transform(input_df)
    shap_vals = explainer.shap_values(X_scaled)[0]
    base_value = explainer.expected_value[1]
    explanation = shap.Explanation(
        values=shap_vals,
        base_values=base_value,
        data=X_scaled,
        feature_names=input_df.columns.tolist()
    )

    tab1, tab2 = st.tabs(["Prediction", "Explanation"])
    with tab1:
        st.metric("Diabetes Risk Score", f"{proba:.2%}")
    with tab2:
        st.subheader("Feature Contributions")
        fig, ax = plt.subplots()
        shap.plots.waterfall(explanation, max_display=10, show=False)
        st.pyplot(fig)


    X_scaled = pipe.named_steps['scaler'].transform(input_df)
    shap_vals = explainer.shap_values(X_scaled)[0]
    base_value = explainer.expected_value[1]

    explanation = shap.Explanation(
        values=shap_vals,
        base_values=base_value,
        data=X_scaled,
        feature_names=input_df.columns.tolist()
    )

    tab1, tab2 = st.tabs(["Prediction", "Explanation"])
    with tab1:
        st.metric("Diabetes Risk Score", f"{proba:.2%}")
    with tab2:
        st.subheader("Feature Contributions")
        fig, ax = plt.subplots()
        shap.plots.waterfall(explanation, max_display=10, show=False)
        st.pyplot(fig)
"""

with open("app.py", "w") as f:
    f.write(streamlit_code)

from pyngrok import ngrok
from google.colab import userdata

# Retrieve the token securely
NGROK_AUTH_TOKEN = userdata.get('NGROK_AUTH_TOKEN')

# Set the token for pyngrok
ngrok.set_auth_token(NGROK_AUTH_TOKEN)

# Example: expose a local port (e.g., Streamlit or FastAPI)
public_url = ngrok.connect(8501)
print("Public URL:", public_url)

!streamlit run app.py &  # Replace with your actual script name

import os

if os.path.exists("requirements.txt"):
    st.write("✅ requirements.txt found")
else:
    st.warning("⚠️ requirements.txt not found")

import os
st.write("Current directory:", os.getcwd())
st.write("Files:", os.listdir())
